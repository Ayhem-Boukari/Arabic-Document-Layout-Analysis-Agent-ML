{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea50b0c4",
   "metadata": {},
   "source": [
    "# 01 - Data Preparation\n",
    "This notebook documents how raw PDFs/images are converted to YOLO format (images + labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "from pathlib import Path\n",
    "print('Notebook scaffold - add your data prep code here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf1867",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "The following cells include the actual scripts used to prepare the dataset from PDFs and organize YOLOv8-ready images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd61d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDFs to images (from convert_pdfs.py)\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "PDF_FOLDER = 'pdfs'\n",
    "OUTPUT_FOLDER = 'all_images'\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith('.pdf')]\n",
    "print(f\"Found {len(pdf_files)} PDF(s).\")\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDFs found. Exiting.\")\n",
    "else:\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(PDF_FOLDER, pdf_file)\n",
    "        print(f\"Converting: {pdf_file}\")\n",
    "        try:\n",
    "            images = convert_from_path(pdf_path)\n",
    "            for i, image in enumerate(images):\n",
    "                image_name = f\"{os.path.splitext(pdf_file)[0]}_page_{i+1}.png\"\n",
    "                image_path = os.path.join(OUTPUT_FOLDER, image_name)\n",
    "                image.save(image_path, 'PNG')\n",
    "            print(f\"Saved {len(images)} image(s) from {pdf_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {pdf_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare YOLO dataset from images and labels (from dataset.py)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "all_images_dir = 'images'\n",
    "all_labels_dir = 'labels'\n",
    "base_output = 'newspaper_yolo'\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(base_output, 'images', split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_output, 'labels', split), exist_ok=True)\n",
    "\n",
    "label_files = [f for f in os.listdir(all_labels_dir) if f.endswith('.txt')]\n",
    "image_label_pairs = []\n",
    "\n",
    "for label_file in label_files:\n",
    "    img_file = label_file.replace('.txt', '.jpg')\n",
    "    img_path = os.path.join(all_images_dir, img_file)\n",
    "    label_path = os.path.join(all_labels_dir, label_file)\n",
    "\n",
    "    if os.path.exists(img_path):\n",
    "        image_label_pairs.append((img_path, label_path))\n",
    "\n",
    "random.shuffle(image_label_pairs)\n",
    "split_idx = int(len(image_label_pairs) * 0.8)\n",
    "train_pairs = image_label_pairs[:split_idx]\n",
    "val_pairs = image_label_pairs[split_idx:]\n",
    "\n",
    "for img, label in train_pairs:\n",
    "    shutil.copy(img, os.path.join(base_output, 'images/train'))\n",
    "    shutil.copy(label, os.path.join(base_output, 'labels/train'))\n",
    "\n",
    "for img, label in val_pairs:\n",
    "    shutil.copy(img, os.path.join(base_output, 'images/val'))\n",
    "    shutil.copy(label, os.path.join(base_output, 'labels/val'))\n",
    "\n",
    "print(\"Dataset prepared for YOLOv8 training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b40f1",
   "metadata": {},
   "source": [
    "# Unified Dataset Builder and Annotation Utilities\n",
    "The next cells embed your real utilities for unifying datasets across categories and adding new annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unified_dataset/build_unified_dataset.py content\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "CATEGORIES = [\"AdminForm\", \"BookCover\", \"Invoice\", \"BusinessCard\", \"Newspaper\"]\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "DEST = Path(\"newspaper_yolo/unified_dataset\")\n",
    "VAL_FRACTION = 0.2\n",
    "RANDOM_SEED = 42\n",
    "DRY_RUN = True  # stay safe when running in notebook; change to False to execute\n",
    "\n",
    "NAMES = [\n",
    "    \"Header\",\"Title\",\"Text\",\"Table\",\"Image\",\"Footer\",\n",
    "    \"Stamp or Signature\",\"Caption\",\"Keyvalue\",\"List-item\",\"Check-box\",\"Formulas\",\n",
    "]\n",
    "\n",
    "\n",
    "def safe_mkdir(p: Path):\n",
    "    if not p.exists():\n",
    "        if not DRY_RUN:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def build_unified():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    images_train = DEST / \"images\" / \"train\"\n",
    "    images_val = DEST / \"images\" / \"val\"\n",
    "    labels_train = DEST / \"labels\" / \"train\"\n",
    "    labels_val = DEST / \"labels\" / \"val\"\n",
    "    for d in [images_train, images_val, labels_train, labels_val]:\n",
    "        safe_mkdir(d)\n",
    "\n",
    "    matched_pairs = []\n",
    "    for cat in CATEGORIES:\n",
    "        cat_root = Path(\"newspaper_yolo\") / cat\n",
    "        img_dir = cat_root / \"images\" / \"train\"\n",
    "        lbl_dir = cat_root / \"labels\" / \"train\"\n",
    "        if not img_dir.exists() or not lbl_dir.exists():\n",
    "            print(f\"[WARN] Skipping {cat}: {img_dir} / {lbl_dir} missing\")\n",
    "            continue\n",
    "        label_stems = {p.stem for p in lbl_dir.glob(\"*.txt\")}\n",
    "        for img in img_dir.iterdir():\n",
    "            if img.suffix.lower() not in IMAGE_EXTS:\n",
    "                continue\n",
    "            if img.stem in label_stems:\n",
    "                lbl = lbl_dir / f\"{img.stem}.txt\"\n",
    "                new_stem = f\"{cat}_{img.stem}\"\n",
    "                matched_pairs.append((img, lbl, new_stem))\n",
    "\n",
    "    print(f\"Found {len(matched_pairs)} matched pairs\")\n",
    "    random.shuffle(matched_pairs)\n",
    "    val_count = int(len(matched_pairs) * VAL_FRACTION)\n",
    "    val_set = set(matched_pairs[:val_count])\n",
    "\n",
    "    for img, lbl, new_stem in matched_pairs:\n",
    "        if (img, lbl, new_stem) in val_set:\n",
    "            img_out = images_val / (new_stem + img.suffix.lower())\n",
    "            lbl_out = labels_val / (new_stem + \".txt\")\n",
    "        else:\n",
    "            img_out = images_train / (new_stem + img.suffix.lower())\n",
    "            lbl_out = labels_train / (new_stem + \".txt\")\n",
    "        if DRY_RUN:\n",
    "            print(f\"COPY {img} -> {img_out}\")\n",
    "            print(f\"COPY {lbl} -> {lbl_out}\")\n",
    "        else:\n",
    "            shutil.copy2(img, img_out)\n",
    "            shutil.copy2(lbl, lbl_out)\n",
    "\n",
    "    data_yaml = {\n",
    "        \"path\": str(DEST.resolve()),\n",
    "        \"train\": \"images/train\",\n",
    "        \"val\": \"images/val\",\n",
    "        \"nc\": len(NAMES),\n",
    "        \"names\": {i: n for i, n in enumerate(NAMES)},\n",
    "    }\n",
    "    if DRY_RUN:\n",
    "        print(\"data.yaml preview:\\n\", yaml.dump(data_yaml, allow_unicode=True, sort_keys=False))\n",
    "    else:\n",
    "        with open(DEST / \"data.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.safe_dump(data_yaml, f, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "# Example: build_unified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unified_dataset/add_new_annotations.py content\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "BASE = Path('newspaper_yolo/unified_dataset')\n",
    "SRC_IMG = BASE / 'new_annotations' / 'images'\n",
    "SRC_LBL = BASE / 'new_annotations' / 'labels'\n",
    "DST_IMG = BASE / 'images' / 'train'\n",
    "DST_LBL = BASE / 'labels' / 'train'\n",
    "\n",
    "ALLOWED_IMG_EXT = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tif', '.tiff'}\n",
    "\n",
    "def next_free_stem(stem: str) -> str:\n",
    "    i = 2\n",
    "    new = stem\n",
    "    while (DST_IMG / f\"{new}.jpg\").exists() or (DST_IMG / f\"{new}.png\").exists() or (DST_LBL / f\"{new}.txt\").exists():\n",
    "        new = f\"{stem}_v{i}\"\n",
    "        i += 1\n",
    "    return new\n",
    "\n",
    "added, skipped = 0, 0\n",
    "DST_IMG.mkdir(parents=True, exist_ok=True)\n",
    "DST_LBL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for img in sorted(SRC_IMG.iterdir()) if SRC_IMG.exists() else []:\n",
    "    if img.suffix.lower() not in ALLOWED_IMG_EXT:\n",
    "        continue\n",
    "    stem = img.stem\n",
    "    lbl = SRC_LBL / f\"{stem}.txt\"\n",
    "    if not lbl.exists():\n",
    "        print(f\"[SKIP] No label for {img.name}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    out_stem = stem\n",
    "    if (DST_LBL / f\"{stem}.txt\").exists() or any((DST_IMG / f\"{stem}{ext}\").exists() for ext in ALLOWED_IMG_EXT):\n",
    "        out_stem = next_free_stem(stem)\n",
    "        print(f\"[RENAME] {stem} -> {out_stem}\")\n",
    "\n",
    "    out_img = DST_IMG / f\"{out_stem}{img.suffix.lower()}\"\n",
    "    out_lbl = DST_LBL / f\"{out_stem}.txt\"\n",
    "\n",
    "    shutil.copy2(img, out_img)\n",
    "    shutil.copy2(lbl, out_lbl)\n",
    "    added += 1\n",
    "\n",
    "print(f\"Done. Added {added} image/label pairs, skipped {skipped}.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
